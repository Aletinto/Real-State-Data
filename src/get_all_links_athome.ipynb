{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Adjust the column width setting to display the full column content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Optionally, adjust the display width if needed\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The objective of this web scrapper is to collect the data of all the real state information available in Luxembourg.\n",
    "\n",
    "There are mainly 2 sources:\n",
    "1. Athome (I will focus on this now)\n",
    "2. Luxhouse maybe later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ideally, we aim to develop a straightforward tool that allows users to retrieve information for selected places through the UI.\n",
    "\n",
    "This approach does not necessitate fetching all available data, which would be considerably more exhaustive.\n",
    "\n",
    "Nonetheless, starting from this point, we have the potential to automate the process using AWS Lambda to gather comprehensive information for all places on a daily basis.\n",
    "\n",
    "For the time being, however, this expanded functionality is not required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to fetch the latest page number for the given type from the athome.lu website.\n",
    "\n",
    "Parameters:\n",
    "    type (str): The type of listing to fetch the latest page number for. Can be either 'vente' or 'location'.\n",
    "\n",
    "Returns:\n",
    "    int: The number of the last page available for the given type. In case the last page link cannot be found, it returns 1.\n",
    "\n",
    "Raises:\n",
    "    ValueError: If the provided type is not 'vente' or 'location'.\n",
    "    requests.exceptions.RequestException: If an error occurs while making the GET request.\n",
    "\n",
    "Example:\n",
    "    The last page number is: 50\n",
    "    50\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_latest_page(url_base: str):\n",
    "\n",
    "    url = url_base\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the 'a' tag with the class 'last' to get the last page link\n",
    "    last_page_tag = soup.find(\"a\", class_=\"last\")\n",
    "\n",
    "    # Extract the href attribute\n",
    "    if last_page_tag:\n",
    "        last_page_link = last_page_tag.get(\"href\")\n",
    "        # Extract the page number from the href\n",
    "        last_page_number = last_page_link.split(\"=\")[-1]\n",
    "        print(f\"The last page number is: {last_page_number}\")\n",
    "    else:\n",
    "        print(\"Could not find the last page link.\")\n",
    "    return int(last_page_number)\n",
    "\n",
    "\n",
    "def get_all_url(page_number: int, url_base: str):\n",
    "    \"\"\"\n",
    "    Fetches and parses URLs from a specific page for a given type of real estate listing.\n",
    "\n",
    "    This function sends an HTTP GET request to a specified page of a real estate\n",
    "    listing type (e.g., 'vente' or 'location') on the `athome.lu` website, parses the\n",
    "    HTML content, extracts all hyperlinks, and filters out unwanted links based on predefined\n",
    "    criteria and patterns.\n",
    "\n",
    "    Args:\n",
    "        page_number (int): The page number of the real estate listings to fetch.\n",
    "        type (str): The type of real estate listing ('vente' or 'location').\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings representing filtered URLs extracted from the page.\n",
    "    \"\"\"\n",
    "\n",
    "    # URL of the web page you want to scrape\n",
    "    \n",
    "    url = url_base + f\"&page={page_number}\"\n",
    "\n",
    "    # url = f\"https://www.athome.lu/en/srp/?tr=rent&q=faee1a4a&loc=L2-luxembourg&ptypes=house%2Cflat%2Cnew-property%2C4%2C7%2C5%2C6%2C42%2C32%2C41%2C43&page={page_number}\"\n",
    "    # url = f\"https://www.athome.lu/srp/?tr=rent&q=a2d9b00c&ptypes=flat\"\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find all 'a' tags (which define hyperlinks)\n",
    "    a_tags = soup.find_all(\"a\")\n",
    "\n",
    "    # Extract the href attributes\n",
    "    links = [a.get(\"href\") for a in a_tags if a.get(\"href\") is not None]\n",
    "\n",
    "    # Remove empty and the following values\n",
    "    values_to_remove = [\n",
    "        \"\",\n",
    "        \"/vente/projet-neuf\",\n",
    "        \"/blog/guides/vente\",\n",
    "        \"/estimer\",\n",
    "        \"/vente/bureau\",\n",
    "        \"/vente/garage-parking\",\n",
    "        \"/vente\",\n",
    "        \"/vente/projet-neuf/lotissement\",\n",
    "        \"/vente?page=5\",\n",
    "        \"/blog/\",\n",
    "        \"/blog/finance-et-assurance/prets-immobilier\",\n",
    "        \"/connexion\",\n",
    "        \"/vente/maison-a-construire/modele-de-maison\",\n",
    "        \"/finance/pret-immobilier\",\n",
    "        \"/vente/maison-a-construire\",\n",
    "        \"/vente/commerce\",\n",
    "        \"/mes-favoris?type=search\",\n",
    "        \"/agences-immobilieres\",\n",
    "        \"/vente/appartement/studio\",\n",
    "        \"/assurance\",\n",
    "        \"https://www.athome.lu/publier\",\n",
    "        \"/vente?page=2085\",\n",
    "        \"/vente?page=4\",\n",
    "        \"/services/demenager\",\n",
    "        \"/vente/terrain\",\n",
    "        \"/vente/maison\",\n",
    "        \"/vendre\",\n",
    "        \"/blog/guides/achat\",\n",
    "        \"/vente?page=1\",\n",
    "        \"/\",\n",
    "        \"/vente/appartement\",\n",
    "        \"/immobilier\",\n",
    "        \"/vente?page=3\",\n",
    "        \"/location\",\n",
    "        \"/mes-favoris\",\n",
    "        \"/finance/partenaires\",\n",
    "        \"/vente/immeuble-de-rapport\",\n",
    "        \"/location/maison\",\n",
    "        \"/blog/guides/location\",\n",
    "        \"/location/appartement/studio\",\n",
    "        \"/location/appartement\",\n",
    "        \"/location/commerce\",\n",
    "        \"/location/bureau\",\n",
    "        \"/location/garage-parking\",\n",
    "        \"/location/terrain\",\n",
    "        \"/location/immeuble-de-rapport\",\n",
    "        \"/location/maison-a-construire\",\n",
    "        \"/location/projet-neuf\",\n",
    "        \"/blog/finance-et-assurance/assurance-habitation\",\n",
    "        \"/vente/projet-neuf/programme-neuf\",\n",
    "        \"/blog/finance-et-assurance/assurance-habitation\",\n",
    "        \"/blog/guides/location\",\n",
    "        \"/location/appartement\",\n",
    "        \"https://www.athome.lu/en/list\",\n",
    "        \"/en/buy\",\n",
    "        \"/location/terrain\",\n",
    "        \"/location/immeuble-rapport\",\n",
    "        \"/location/maison-a-construire\",\n",
    "        \"/location/projet-neuf\",\n",
    "        \"/blog/finance-et-assurance/assurance-habitation\",\n",
    "        \"/vente/projet-neuf/programme-neuf\",\n",
    "        \"/blog/finance-et-assurance/assurance-habitation\",\n",
    "        \"/blog/guides/location\",\n",
    "        \"/location/appartement\",\n",
    "        \"https://www.athome.lu/en/list\",\n",
    "        \"https://www.athome.lu\",\n",
    "        \"https://www.athome.lu/en/list\",\n",
    "        \"https://www.athome.lu/en/insurance\",\n",
    "        \"https://www.athome.lu/en/services/move\",\n",
    "        \"https://www.athome.lu/en/sell\",\n",
    "        \"https://www.athome.lu/en/estimate\",\n",
    "        \"https://www.athome.lu/en/rent\",\n",
    "        \"https://www.athome.lu/en/buy\",\n",
    "        \"https://www.athome.lu/en/finance/mortgage\",\n",
    "        \"https://www.athome.lu/en/srp/?tr=rent&q=faee1a4a&loc=L2-luxembourg&ptypes=house%2Cflat%2Cnew-property%2C4%2C7%2C5%2C6%2C42%2C32%2C41%2C43&page=95\",\n",
    "        \"https://www.athome.lu/en/connect\",\n",
    "        \"https://www.athome.lu/en/my-favourites\",\n",
    "        \"https://www.athome.lu/en/my-favourites?type=search\",\n",
    "        \"https://www.athome.lu/en/finance/partners\",\n",
    "        \"https://www.athome.lu/en/\",\n",
    "        \"https://www.athome.lu/en/srp/?tr=rent&q=faee1a4a&loc=L2-luxembourg&ptypes=house%2Cflat%2Cnew-property%2C4%2C7%2C5%2C6%2C42%2C32%2C41%2C43&page=1\",\n",
    "        \"https://www.athome.lu/en/rent\",\n",
    "        \"https://www.athome.lu/en/insurance\",\n",
    "        \"https://www.athome.lu/en/finance/mortgage\",\n",
    "        \"https://www.athome.lu/en/services/move\",\n",
    "        \"https://www.athome.lu/en/sell\",\n",
    "        \"https://www.athome.lu/en/estimate\",\n",
    "        \"https://www.athome.lu/en/my-favourites\",\n",
    "        \"https://www.athome.lu/en/srp/?tr=rent&q=faee1a4a&loc=L2-luxembourg&ptypes=house%2Cflat%2Cnew-property%2C4%2C7%2C5%2C6%2C42%2C32%2C41%2C43&page=95\",\n",
    "        \"https://www.athome.lu/en/finance/partners\",\n",
    "        \"https://www.athome.lu/en/\",\n",
    "        \"https://www.athome.lu/en/my-favourites?type=search\",\n",
    "        \"https://www.athome.lu/en/connect\",\n",
    "    ]\n",
    "\n",
    "    # Filter out unwanted links\n",
    "    links = [link for link in links if link not in values_to_remove]\n",
    "\n",
    "    # Patterns to be removed\n",
    "    pattern1 = re.compile(r\"/vente\\?page=\\d+\")\n",
    "    pattern2 = re.compile(r\"/location\\?page=\\d+\")\n",
    "    pattern3 = re.compile(r\"/agence\\?page=\\d+\")\n",
    "    pattern4 = re.compile(r\"https?://[^/]+/agence/\\d+\")\n",
    "    pattern5 = re.compile(r\"https?://[^/]+/vente\\?page=\\d+\")\n",
    "    pattern6 = re.compile(r\"https?://[^/]+/location\\?page=\\d+\")\n",
    "    pattern7 = re.compile(r\"https?://www\\.athome\\.lu/realestate-agent/\\d+\")\n",
    "\n",
    "    # Filter out links\n",
    "    links = [\n",
    "        link\n",
    "        for link in links\n",
    "        if not (\n",
    "            pattern1.search(link)\n",
    "            or pattern2.search(link)\n",
    "            or pattern3.search(link)\n",
    "            or pattern4.search(link)\n",
    "            or pattern5.search(link)\n",
    "            or pattern6.search(link)\n",
    "            or pattern7.search(link)\n",
    "        )\n",
    "    ]\n",
    "    return links\n",
    "\n",
    "\n",
    "def scraper_thread(page, all_links, url_base):\n",
    "    \"\"\"\n",
    "    Scraper thread function for fetching URLs from a specific page.\n",
    "\n",
    "    This function is designed to be used as a thread in conjunction with a ThreadPoolExecutor. \n",
    "    It fetches URLs from a specified page of a given type of real estate listing, wraps the \n",
    "    results in a dictionary, and appends this dictionary to the provided list.\n",
    "\n",
    "    Args:\n",
    "        page (int): The page number to scrape.\n",
    "        type (str): The type of real estate listing ('vente' or 'location').\n",
    "        all_links (list): A list to which the function will append a dictionary containing the \n",
    "                          page number and the collected links.\n",
    "        url_base (str): The base URL to use for scraping.\n",
    "\n",
    "    Returns:\n",
    "        None as it appends to the all_links\n",
    "    \"\"\"\n",
    "\n",
    "    page_links = get_all_url(page_number = page, url_base = url_base)\n",
    "    temp_dict = {\"page\": page, \"links\": page_links}\n",
    "    all_links.append(temp_dict)\n",
    "    print(f\"Page {page} done\")\n",
    "\n",
    "\n",
    "\n",
    "def get_all_links(threads, url_base: str,last_page_number):\n",
    "    \"\"\"\n",
    "    Collects all available links for a specified type of real estate listing using multithreading.\n",
    "\n",
    "    This function retrieves URLs from multiple pages of either 'vente' or 'location' \n",
    "    real estate listings on the `athome.lu` website. It employs multithreading via\n",
    "    `ThreadPoolExecutor` to expedite the fetching process. The collected URLs are then\n",
    "    structured into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        TYPE (str): The type of real estate listing ('vente' or 'location').\n",
    "        threads (int): The number of threads to use for concurrent URL fetching.\n",
    "        url_base (str): The base URL for the real estate listings.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the collected URLs along with their \n",
    "                          corresponding pages and types. The DataFrame includes columns\n",
    "                          'page', 'href', 'type', and 'link'.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the 'TYPE' argument is not either 'vente' or 'location'.\n",
    "    \"\"\"\n",
    "\n",
    "    all_links = []\n",
    "    max_threads = threads\n",
    "        \n",
    "    with ThreadPoolExecutor(max_threads) as executor:\n",
    "        futures = [executor.submit(scraper_thread, url_base, page, all_links) for page in range(1, last_page_number + 1)]\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            all_links.append(result)\n",
    "\n",
    "    # Format Data\n",
    "    flattened_data = []\n",
    "\n",
    "    for item in all_links:\n",
    "        if item:\n",
    "            page = item['page']\n",
    "            for link in item['links']:\n",
    "                flattened_data.append({'page': page, 'href': link, 'type': TYPE})\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(flattened_data).sort_values(by='page')\n",
    "    df['link'] = 'https://www.athome.lu' + df['href']\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last page number is: 9\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Fetches rental flat URLs from the specified base URL and saves them into a pickle file.\n",
    "    \"\"\"\n",
    "    url_base = \"https://www.athome.lu/srp/?tr=rent&q=a2d9b00c&ptypes=flat\"\n",
    "    last_page_number = get_latest_page(url_base)\n",
    "    list_of_links = []\n",
    "\n",
    "    for i in range(1, last_page_number + 1):\n",
    "        outcome = get_all_url(page_number=i, url_base=url_base)\n",
    "        list_of_links.extend(outcome)\n",
    "\n",
    "    with open(\"list_of_links.pkl\", \"wb\") as f:\n",
    "        pickle.dump(list_of_links, f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
